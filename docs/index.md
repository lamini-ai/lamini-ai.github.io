# Overview
## Welcome to Lamini 🦙

Lamini is an integrated LLM inference and tuning platform, so you can seamlessly tune models that achieve exceptional factual accuracy while minimizng latency and cost. Lamini Enterprise runs in your environment - even air-gapped - or you can use our GPUs in Lamini Cloud.

<table>
  <tr>
    <th>Goal 🏁</th>
    <th>Go to 🔗</th>
  </tr>
  <tr onclick="location.href='/inference/quick_tour'">
    <td>2 steps to start using LLMs on Lamini Cloud ☁️</td>
    <td><a href="/inference/quick_tour">Quick Start</a></td>
  </tr>
  <tr onclick="location.href='/inference/json_output/'">
    <td>LLM inference that's 100% guaranteed to match your schema 💯</td>
    <td><a href="/inference/json_output/">JSON output</a></td>
  </tr>
  <tr onclick="location.href='/inference/batching/'">
    <td>High throughput inference (52x faster) 🏃💨</td>
    <td><a href="/inference/batching/">Iteration batching</a></td>
  </tr>
  <tr onclick="location.href='/about'">
    <td>What makes Lamini unique? ✨</td>
    <td><a href="/about">About</a></td>
  </tr>
  <tr onclick="location.href='https://github.com/lamini-ai/lamini-sdk/';">
    <td>Use cases and recipes 🥘</td>
    <td><a href="https://github.com/lamini-ai/lamini-sdk/">Examples</a></td>
  </tr>
</table>
