# Overview
## Welcome to Lamini ğŸ¦™

Lamini is an integrated LLM inference and tuning platform, so you can seamlessly tune models that achieve exceptional factual accuracy while minimizng latency and cost. Lamini Enterprise runs in your environment - even air-gapped - or you can use our GPUs in Lamini Cloud.

<table>
  <tr>
    <th>Goal ğŸ</th>
    <th></th>
    <th>Go to ğŸ”—</th>
  </tr>
  <tr onclick="location.href='/inference/quick_start'">
    <td>2 steps to start using LLMs on Lamini Cloud â˜ï¸</td>
    <td></td>
    <td><a href="/inference/quick_start">Quick Start</a></td>
  </tr>
  <tr onclick="location.href='/tuning/memory_tuning/'">
    <td>95% accuracy and beyond ğŸ§ </td>
    <td></td>
    <td><a href="/tuning/memory_tuning/">Memory Tuning</a></td>
  </tr>
  <tr onclick="location.href='/inference/json_output/'">
    <td>LLM inference that's 100% guaranteed to match your schema ğŸ’¯</td>
    <td></td>
    <td><a href="/inference/json_output/">JSON Output</a></td>
  </tr>
  <tr onclick="location.href='/inference/batching/'">
    <td>High throughput inference (52x faster) ğŸƒğŸ’¨</td>
    <td></td>
    <td><a href="/inference/batching/">Iteration Batching</a></td>
  </tr>
  <tr onclick="location.href='/about'">
    <td>What makes Lamini unique? âœ¨</td>
    <td></td>
    <td><a href="/about">About</a></td>
  </tr>
  <tr onclick="location.href='https://github.com/lamini-ai/lamini-sdk/';">
    <td>Use cases and recipes ğŸ¥˜</td>
    <td></td>
    <td><a href="https://github.com/lamini-ai/lamini-sdk/">Examples</a></td>
  </tr>
</table>
